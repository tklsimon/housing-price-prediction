{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f8a320-8837-4f5f-a18e-576bb5d81436",
   "metadata": {},
   "source": [
    "# STAT8107 Data Mining Techniques\n",
    "## Group Project\n",
    "\n",
    "**Members (UID):**  \n",
    "TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c31f2-661c-4abe-bd13-a992fea85b5c",
   "metadata": {},
   "source": [
    "# Import modules and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4add046-de89-4ba2-b5e1-7b8b37388a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from typing import List\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416fb4ae-5ff0-419e-be23-bfd11840f4ea",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accee50a-78a3-49c9-bc77-1315736cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_add_labels(x: List[str],\n",
    "                   y: List[int]) -> None:\n",
    "    y_scale = y.mean()/100\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i]+y_scale, y[i], ha = 'center')\n",
    "\n",
    "def print_missing_val_count(df: pd.DataFrame) -> None:\n",
    "    # Missing value counts\n",
    "    df_na_cnt = df.isnull().sum()\n",
    "    df_record_cnt = df.shape[0]\n",
    "    \n",
    "    # Print the count of missing value for each feature\n",
    "    if df_na_cnt.sum() > 0:\n",
    "        print(\"The following columns have missing values:\")\n",
    "        for col, na_cnt in zip(df_na_cnt.index, df_na_cnt.values):\n",
    "            if na_cnt > 0:\n",
    "                print(f\"{col} has {na_cnt} ({100*na_cnt/df_record_cnt:0.1f}%) missing value.\")\n",
    "    else:\n",
    "        print(\"The dataframe does not have missing values.\")\n",
    "\n",
    "def knn_imputation(df: pd.DataFrame,\n",
    "                   feature_columns: List[str],\n",
    "                   target_column: str) -> None:\n",
    "    \"\"\"\n",
    "    :param df: Dataframe for missing value imputation\n",
    "    :param feature_columns: list of feature names (string) for knn imputation\n",
    "    :param target_column: feature name (string) to be imputed\n",
    "    :return Nothing\n",
    "    \"\"\"\n",
    "    # Fit KNN model with records have non-null value in target column\n",
    "    df_clean = df[~df[target_column].isna()]\n",
    "    knn = KNeighborsRegressor(p=1, n_neighbors=3)\n",
    "    knn.fit(df_clean[feature_columns], df_clean[target_column])\n",
    "    # Predict the missing values\n",
    "    df_miss = df[df[target_column].isna()]\n",
    "    if df_miss.shape[0] > 0:\n",
    "        y_pred = knn.predict(df_miss[feature_columns])\n",
    "        # Impute the missing values\n",
    "        df.loc[df[target_column].isna(), target_column] = y_pred\n",
    "        print(f\"Missing values in {target_column} has been imputed.\")\n",
    "    else:\n",
    "        print(f\"There is no missing values in {target_column}. No action.\")\n",
    "\n",
    "def one_hot_encoding(df: pd.DataFrame,\n",
    "                     column:str) -> pd.DataFrame:\n",
    "    distinct_values = set(df[column])\n",
    "    \n",
    "    for value in distinct_values:\n",
    "        new_column = column + \"_\" + value\n",
    "        df[new_column] = df[column].apply(lambda x: 1 if x == value else 0)\n",
    "    \n",
    "    df = df.drop(column, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def regression_report(y_test: List[float],\n",
    "                      y_pred: List[float],\n",
    "                      p: int) -> str:\n",
    "    n = y_test.shape[0]\n",
    "    \n",
    "    root_mse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    \n",
    "    metrics = f\"\\\n",
    "Rooted-MSE: {root_mse:.4}\\n\\\n",
    "MAE: {mae:.4}\\n\\\n",
    "Adjusted R-Squared: {adj_r2:.4f}\"\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def predict_with_regressor(regressor: \"sklearn.regressor\",\n",
    "                           X_train: pd.DataFrame,\n",
    "                           X_test: pd.DataFrame,\n",
    "                           y_train: List[float],\n",
    "                           y_test: List[float]) -> None:\n",
    "    y_pred = regressor.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    print(\"---------- \" + regressor.__class__.__name__ + \" ----------\")\n",
    "    print(regression_report(y_test, y_pred, X_train.shape[1]))\n",
    "    print(\"\")\n",
    "\n",
    "def predict_with_regressors(regressors, X_train, X_test, y_train, y_test) -> None:\n",
    "    for regressor in regressors(0):\n",
    "        predict_with_regressor(regressor, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d172dd8-5baf-4048-b18b-866ba8ccbeab",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ea3ed5-4686-4706-a99c-45cca996cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files\n",
    "price_train_df = pd.read_csv('trainPrice.csv')\n",
    "price_test_df = pd.read_csv('testPrice.csv')\n",
    "school_df = pd.read_csv('Schools.csv')\n",
    "subway_df = pd.read_csv('Subways.csv')\n",
    "submission_price_df = pd.read_csv('submissionPrice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22eff2-2e59-4592-9189-9246d83c08d1",
   "metadata": {},
   "source": [
    "## 2.2 Input Files and Their Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80923aab-d459-42c5-bd4a-46e5d9c846a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1601458 entries, 0 to 1601457\n",
      "Data columns (total 25 columns):\n",
      " #   Column                              Non-Null Count    Dtype  \n",
      "---  ------                              --------------    -----  \n",
      " 0   key                                 1601458 non-null  int64  \n",
      " 1   apartment_id                        1601458 non-null  int64  \n",
      " 2   city                                1601458 non-null  int64  \n",
      " 3   transaction_year_month              1601458 non-null  int64  \n",
      " 4   transaction_date                    1601458 non-null  object \n",
      " 5   year_of_completion                  1601458 non-null  int64  \n",
      " 6   exclusive_use_area                  1601458 non-null  float64\n",
      " 7   floor                               1601458 non-null  int64  \n",
      " 8   latitude                            1601458 non-null  float64\n",
      " 9   longitude                           1601458 non-null  float64\n",
      " 10  address_by_law                      1601458 non-null  int64  \n",
      " 11  total_parking_capacity_in_site      1509645 non-null  float64\n",
      " 12  total_household_count_in_sites      1601458 non-null  int64  \n",
      " 13  apartment_building_count_in_sites   1601458 non-null  int64  \n",
      " 14  tallest_building_in_sites           1601449 non-null  float64\n",
      " 15  lowest_building_in_sites            1601449 non-null  float64\n",
      " 16  heat_type                           1599441 non-null  object \n",
      " 17  heat_fuel                           1591791 non-null  object \n",
      " 18  room_id                             1601458 non-null  int64  \n",
      " 19  supply_area                         1601458 non-null  float64\n",
      " 20  total_household_count_of_area_type  1601458 non-null  int64  \n",
      " 21  room_count                          1600767 non-null  float64\n",
      " 22  bathroom_count                      1600767 non-null  float64\n",
      " 23  front_door_structure                1587566 non-null  object \n",
      " 24  transaction_real_price              1601458 non-null  int64  \n",
      "dtypes: float64(9), int64(12), object(4)\n",
      "memory usage: 305.5+ MB\n"
     ]
    }
   ],
   "source": [
    "price_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d8af34-cbe7-4203-a3f7-797768b4e541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# price_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6346a0-75d2-42a4-9294-1e540ba83ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3918 entries, 0 to 3917\n",
      "Data columns (total 25 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   key                                 3918 non-null   int64  \n",
      " 1   apartment_id                        3918 non-null   int64  \n",
      " 2   city                                3918 non-null   int64  \n",
      " 3   transaction_year_month              3918 non-null   int64  \n",
      " 4   transaction_date                    3918 non-null   object \n",
      " 5   year_of_completion                  3918 non-null   int64  \n",
      " 6   exclusive_use_area                  3918 non-null   float64\n",
      " 7   floor                               3918 non-null   int64  \n",
      " 8   latitude                            3918 non-null   float64\n",
      " 9   longitude                           3918 non-null   float64\n",
      " 10  address_by_law                      3918 non-null   int64  \n",
      " 11  total_parking_capacity_in_site      3547 non-null   float64\n",
      " 12  total_household_count_in_sites      3918 non-null   int64  \n",
      " 13  apartment_building_count_in_sites   3918 non-null   int64  \n",
      " 14  tallest_building_in_sites           3917 non-null   float64\n",
      " 15  lowest_building_in_sites            3917 non-null   float64\n",
      " 16  heat_type                           3890 non-null   object \n",
      " 17  heat_fuel                           3870 non-null   object \n",
      " 18  room_id                             3918 non-null   int64  \n",
      " 19  supply_area                         3918 non-null   float64\n",
      " 20  total_household_count_of_area_type  3918 non-null   int64  \n",
      " 21  room_count                          3913 non-null   float64\n",
      " 22  bathroom_count                      3913 non-null   float64\n",
      " 23  front_door_structure                3873 non-null   object \n",
      " 24  transaction_real_price              3918 non-null   int64  \n",
      "dtypes: float64(9), int64(12), object(4)\n",
      "memory usage: 765.4+ KB\n"
     ]
    }
   ],
   "source": [
    "price_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f5708d-1ce9-42cd-97e3-8b94c440a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f19a1f-982b-469f-9c97-9bfcd38fef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Training Set to Price Data Set\n",
    "price_df = price_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a21535-1d5e-488a-b130-bb09ff7ab619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1921 entries, 0 to 1920\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   school_code      1921 non-null   object \n",
      " 1   latitude         1921 non-null   float64\n",
      " 2   longitude        1921 non-null   float64\n",
      " 3   school_class     1921 non-null   object \n",
      " 4   operation_type   1921 non-null   object \n",
      " 5   highschool_type  462 non-null    object \n",
      " 6   gender           1921 non-null   object \n",
      " 7   foundation_date  1921 non-null   object \n",
      " 8   address_by_law   1921 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 135.2+ KB\n"
     ]
    }
   ],
   "source": [
    "school_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a6c651-0057-474f-bccf-ac9cfd3b779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# school_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23e0a95-fbc6-4cfa-8850-88fa6e2e48ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 405 entries, 0 to 404\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   station_id      405 non-null    int64  \n",
      " 1   latitude        405 non-null    float64\n",
      " 2   longitude       405 non-null    float64\n",
      " 3   subway_line     405 non-null    object \n",
      " 4   address_by_law  396 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 15.9+ KB\n"
     ]
    }
   ],
   "source": [
    "subway_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83caf526-2985-4e89-97a6-358c86ceab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subway_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee7434c2-a236-44d6-832d-a893eccbc82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3918 entries, 0 to 3917\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype\n",
      "---  ------                  --------------  -----\n",
      " 0   key                     3918 non-null   int64\n",
      " 1   transaction_real_price  3918 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 61.3 KB\n"
     ]
    }
   ],
   "source": [
    "submission_price_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5243434-d888-4d78-8159-b68b41efdf2c",
   "metadata": {},
   "source": [
    "# 2.3 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46ad9a-afff-47ce-890d-926ceb918fe6",
   "metadata": {},
   "source": [
    "## 2.3.1 Price Data Set (trainPrice.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06a458-c832-4d3c-a965-b2f764467fad",
   "metadata": {},
   "source": [
    "## 2.3.1.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d821037-2f63-4cde-8a74-0c04df4e91ad",
   "metadata": {},
   "source": [
    "## Field - city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2df21a65-258c-4c0a-bdb0-db69564e7700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct values\n",
    "price_df[\"city\"].drop_duplicates().sort_values().to_list() # There are only 2 distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0514d40b-606d-4e88-b058-7c5b3aedce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>35.117560</td>\n",
       "      <td>129.011018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>35.118632</td>\n",
       "      <td>129.010886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>35.081732</td>\n",
       "      <td>129.019474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude   longitude\n",
       "1491  35.117560  129.011018\n",
       "1492  35.118632  129.010886\n",
       "1493  35.081732  129.019474"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample few (latitude, longitude) pairs from records with city = 0\n",
    "price_df[price_df[\"city\"] == 0][[\"latitude\", \"longitude\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f39cb13-76ee-4a13-8948-c309e877213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.585965</td>\n",
       "      <td>127.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.585965</td>\n",
       "      <td>127.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.580511</td>\n",
       "      <td>127.014016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude\n",
       "0  37.585965  127.000231\n",
       "1  37.585965  127.000231\n",
       "2  37.580511  127.014016"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample few (latitude, longitude) pairs from records with city = 1\n",
    "price_df[price_df[\"city\"] == 1][[\"latitude\", \"longitude\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93971d5a-6cfa-4162-b95f-4d7603591ce6",
   "metadata": {},
   "source": [
    "## Field - transaction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2a7128-41a4-4464-b0ab-4156a20d582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values in column transaction_date are '11~20', '1~10', '21~28', '21~29', '21~30', '21~31'\n"
     ]
    }
   ],
   "source": [
    "print(\"Distinct values in column transaction_date are\", str(sorted(set(price_df['transaction_date'])))[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52c23a-47f0-41d1-8622-35755a697e89",
   "metadata": {},
   "source": [
    "## Field - transaction_real_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d27f858a-0811-4da7-afa0-0b63e5f14dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram of Transaction Real Price\n",
    "# fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# plt.hist(price_df[\"transaction_real_price\"]/1000000, bins=100)\n",
    "# plt.title('Histogram of Transaction Real Price')\n",
    "# plt.xlabel('Transaction Real Price ($1,000,000)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e8c7e9c-862c-41b4-ad8b-bbca6a2608e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum transaction price is $8200 M\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum transaction price is ${int(price_df['transaction_real_price'].max()/1000000)} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd718e-e8ee-41bf-b830-2a66a1f6a601",
   "metadata": {},
   "source": [
    "## Field - transaction_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d9ca795-dcc1-4c77-b56f-8a9bc0fabb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot of Transaction Year Month\n",
    "# # Drop missing values (NA) and calculate the counts of each value\n",
    "# val_count = price_df[\"transaction_year_month\"].dropna().astype(\"str\").value_counts()\n",
    "# val_count = val_count.sort_index()\n",
    "\n",
    "# val_mean = val_count.mean()\n",
    "\n",
    "# # Draw bar plot\n",
    "# fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# plt.bar(val_count.index, val_count.values)\n",
    "# plt.title('Bar Plot of Transaction Year Month')\n",
    "# plt.xlabel('Transaction Year Month')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(range(len(val_count.index))[::2], val_count.index[::2], rotation=90)\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"The mean of transaction count per month is {val_mean:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c69496-b0d1-4299-9008-2ef2d62e8d00",
   "metadata": {},
   "source": [
    "## Fields - total_parking_capacity_in_site, total_household_count_in_sites, room_count and bathroom_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e39232-25f6-4563-9e5d-b4c20baac8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a figure and add the axes for subgraphs\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "# # Histogram of Total Parking Capacity\n",
    "# axes[0,0].hist(price_df[\"total_parking_capacity_in_site\"], bins=30)\n",
    "# axes[0,0].set(title='Histogram of Total Parking Capacity')\n",
    "# axes[0,0].set_xlabel('Total Parking Capacity')\n",
    "# axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# # Histogram of Total Household Count\n",
    "# axes[0,1].hist(price_df[\"total_household_count_in_sites\"], bins=30)\n",
    "# axes[0,1].set(title='Histogram of Total Household Count')\n",
    "# axes[0,1].set_xlabel('Total Household Count')\n",
    "# axes[0,1].set_ylabel('Count')\n",
    "\n",
    "# # # Bar plot of Room Count\n",
    "# val_count = price_df[\"room_count\"].dropna().value_counts() / 1000\n",
    "# val_count = val_count.sort_index()\n",
    "# axes[1,0].bar(val_count.index, val_count.values)\n",
    "# axes[1,0].set(title='Bar Plot of Room Count')\n",
    "# axes[1,0].set_xlabel('Room Count')\n",
    "# axes[1,0].set_ylabel('Count (1,000)')\n",
    "\n",
    "# # # Bar plot of Bathroom Count\n",
    "# val_count = price_df[\"bathroom_count\"].dropna().value_counts() / 1000\n",
    "# val_count = val_count.sort_index()\n",
    "# axes[1,1].bar(val_count.index, val_count.values)\n",
    "# axes[1,1].set(title='Bar Plot of Bathroom Count')\n",
    "# axes[1,1].set_xlabel('Bathroom Count')\n",
    "# axes[1,1].set_ylabel('Count (1,000)')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36ee4e3e-44af-4503-90a3-fdf333f712cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precentage of records have 2-4 rooms: 96%\n",
      "Precentage of ecords have 1 or 2 bathrooms: 99%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precentage of records have 2-4 rooms: \\\n",
    "{100 * price_df[price_df['room_count'].isin([2,3,4])].shape[0] / price_df.shape[0]:.0f}%\")\n",
    "print(f\"Precentage of ecords have 1 or 2 bathrooms: \\\n",
    "{100 * price_df[price_df['bathroom_count'].isin([1,2])].shape[0] / price_df.shape[0]:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82bf7984-62b5-42ff-b152-bc8810fd0b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of room_count and bathroom_count are 2.95 and 1.59 respectively.\n",
      "The mode of room_count and bathroom_count are 3 and 2 respectively.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean of room_count and bathroom_count are \\\n",
    "{price_df['room_count'].mean():.2f} and {price_df['bathroom_count'].mean():.2f} respectively.\")\n",
    "print(f\"The mode of room_count and bathroom_count are \\\n",
    "{price_df['room_count'].mode()[0]:.0f} and {price_df['bathroom_count'].mode()[0]:.0f} respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a729c-9aad-4442-a8dd-e79ad75cd29a",
   "metadata": {},
   "source": [
    "## 2.3.1.2 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd2052-3ec9-471d-8da9-fe89b2c47748",
   "metadata": {},
   "source": [
    "## Fields - transaction_year_month and transaction_real_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cb4e90c-be07-4d86-8799-ca9221052ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw bar plot\n",
    "# price_mth_mean = price_df.groupby(['transaction_year_month'])['transaction_real_price'].mean().reset_index()\n",
    "# price_year_mth = price_mth_mean['transaction_year_month'].astype(\"str\")\n",
    "# price_mean = price_mth_mean['transaction_real_price'] / 1000000\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# plt.bar(price_year_mth, price_mean)\n",
    "# plt.title('Bar Plot of Mean Price for Each Month')\n",
    "# plt.xlabel('Transaction Year Month')\n",
    "# plt.ylabel('Mean Price ($1,000,000)')\n",
    "# plt.xticks(range(len(price_year_mth))[::2], price_year_mth[::2], rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b376e1b-1f86-447f-bb24-b753e9f1407f",
   "metadata": {},
   "source": [
    "## Fields - room_count and transaction_real_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0823c4a7-5bc7-4b9e-a7e8-e1ff8cc873dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a figure and add the axes for subgraphs\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 8))\n",
    "\n",
    "# for i in [2,3,4]:\n",
    "#     room_cnt_price = price_df[price_df['room_count'] == i][\"transaction_real_price\"] / 1000000\n",
    "\n",
    "#     axes[i-2].boxplot(room_cnt_price, vert=False) # showfliers=False\n",
    "#     axes[i-2].set_xlabel('Transaction Price ($1,000,000)')\n",
    "#     axes[i-2].set_ylabel(f'Room Count = {i}')\n",
    "#     axes[i-2].set_yticks([])\n",
    "\n",
    "# fig.suptitle('Transaction Price Distribution with different Room Count')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094d41d-e9ed-4f14-8a6d-3ac65751a598",
   "metadata": {},
   "source": [
    "## Fields - bathroom_count and transaction_real_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c724a4cf-1b21-419e-b4a4-83076de9eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a figure and add the axes for subgraphs\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 8))\n",
    "\n",
    "# for i in [1,2]:\n",
    "#     room_cnt_price = price_df[price_df['bathroom_count'] == i][\"transaction_real_price\"] / 1000000\n",
    "\n",
    "#     axes[i-1].boxplot(room_cnt_price, vert=False) # showfliers=False\n",
    "#     axes[i-1].set_xlabel('Transaction Price ($1,000,000)')\n",
    "#     axes[i-1].set_ylabel(f'Bathroom Count = {i}')\n",
    "#     axes[i-1].set_yticks([])\n",
    "\n",
    "# fig.suptitle('Transaction Price Distribution with different Bathroom Count')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d8c7d-e1d8-474a-8bed-778b4cf8bdca",
   "metadata": {},
   "source": [
    "## Fields - city, latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f88741ed-24c0-4ffc-9707-0b2349ad3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample 1000 records from each class\n",
    "# price_sample = price_df.groupby('city').apply(lambda x: x.sample(1000))\n",
    "\n",
    "# # Scatter Plot of Latitude and Longitude with city labels\n",
    "# scatter = plt.scatter(price_sample['longitude'], price_sample['latitude'], c=price_sample['city'], cmap='summer')\n",
    "# plt.title('Latitude and Longitude of City')\n",
    "# plt.xlabel('Longitude')\n",
    "# plt.ylabel('Latitude')\n",
    "# plt.legend(*scatter.legend_elements(), loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc839aa-2b4e-41be-b6ee-d014493f02ce",
   "metadata": {},
   "source": [
    "## Fields - All Numeric Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b76b6b1-d94e-4512-9a81-de09b8d0cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_df.corr() \\\n",
    "#     .style \\\n",
    "#     .background_gradient(cmap='coolwarm') \\\n",
    "#     .set_precision(2) \\\n",
    "#     .set_table_styles([dict(selector=\"th.col_heading\",props=[(\"writing-mode\", \"vertical-rl\")])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb046a6e-22ab-43e1-a6f1-ed758ae7ef8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.3.2 School Data Set (Schools.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71ff63-7ad4-4670-afba-9731611d71ba",
   "metadata": {},
   "source": [
    "## 2.3.2.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ce473-fab6-4327-a357-00c6b2fdf5ea",
   "metadata": {},
   "source": [
    "## Field - school_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "408fea6c-ede6-478a-80f3-aee89ef10c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pie chart of School Class\n",
    "# # Drop missing values (NA) and calculate the counts of each value\n",
    "# val_count = school_df[\"school_class\"].dropna().astype(\"str\").value_counts()\n",
    "\n",
    "# # Draw pie chart\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))\n",
    "# plt.title('Pie Chart of School Class')\n",
    "# plt.pie(val_count.values, labels = val_count.index, autopct='%1.1f%%')\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49b632-e1ae-4b96-9c71-acfc373a270e",
   "metadata": {},
   "source": [
    "## Field - operation_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ee7b955-fd75-4d3e-a39f-52a710c1b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot of Operation Type of Schools\n",
    "# # Drop missing values (NA) and calculate the counts of each value\n",
    "# val_count = school_df[\"operation_type\"].dropna().astype(\"str\").value_counts()\n",
    "\n",
    "# # Draw bar plot\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# plt.bar(val_count.index, val_count.values)\n",
    "# plt.title('Bar Plot of Operation Type of Schools')\n",
    "# plt.xlabel('Operation Type')\n",
    "# plt.ylabel('Count')\n",
    "# plt_add_labels(val_count.index, val_count.values)\n",
    "# plt.xticks(range(len(val_count.index)), val_count.index)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d71e169-5060-4435-967d-1ad10073f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precentage of public schools: 75.2%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precentage of public schools: {100 * school_df[school_df['operation_type'] == 'public'].shape[0] / school_df.shape[0]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e419631-61ec-4813-acef-fa1eaae9ad64",
   "metadata": {},
   "source": [
    "## Field - highschool_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac1489e2-c6ee-47f0-a946-bd822720e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pie chart of High School Type\n",
    "# # Drop missing values (NA) and calculate the counts of each value\n",
    "# val_count = school_df[\"highschool_type\"].dropna().astype(\"str\").value_counts()\n",
    "\n",
    "# # Draw pie chart\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# plt.title('Pie Chart of High School Type')\n",
    "# plt.pie(val_count.values, labels = val_count.index, autopct='%1.1f%%')\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "798f04b6-e1d6-4d3a-b00d-fcc4f318abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The school classes with NULL high school type: 'elementary', 'middle'\n"
     ]
    }
   ],
   "source": [
    "print(f\"The school classes with NULL high school type: \\\n",
    "{str(list(school_df[school_df['highschool_type'].isna()]['school_class'].drop_duplicates()))[1:-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589e6ce-d10d-4bbc-97e4-1ff3484f94ef",
   "metadata": {},
   "source": [
    "## Field - gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6238c03-fdab-4b06-b138-c43a0d6e8b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both      1524\n",
       "male       199\n",
       "female     198\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_df[\"gender\"].dropna().astype(\"str\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb0a3d-b3e4-4bad-a1b3-8e5542df70ea",
   "metadata": {},
   "source": [
    "## 2.3.2.2 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67529c-b7f4-493b-ab20-f56d8fe91b8b",
   "metadata": {},
   "source": [
    "## Fields - school_class and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51de1c9e-bb6b-4696-84e9-c2dc221abe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack Bar Plot of School Class and Gender\n",
    "# class_gender_cnt = school_df.groupby(['school_class', 'gender']).size().reset_index(name='count')\n",
    "# class_gender_cnt = class_gender_cnt.pivot(index='school_class', columns='gender', values='count')\n",
    "# class_gender_cnt.reset_index(inplace=True)\n",
    "# class_gender_cnt['school_class'] = pd.Categorical(class_gender_cnt['school_class'], [\"elementary\", \"middle\", \"high\"])\n",
    "# class_gender_cnt = class_gender_cnt.sort_values(\"school_class\")\n",
    "\n",
    "# class_gender_cnt.plot(\n",
    "#     x = 'school_class', \n",
    "#     kind = 'barh', \n",
    "#     stacked = True, \n",
    "#     title = 'Stacked Bar Plot of Class and Gender', \n",
    "#     mark_right = True) \n",
    "\n",
    "# plt.xlabel('Count')\n",
    "# plt.ylabel('School Calss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7136e4-7bbf-493e-a699-643fe202643d",
   "metadata": {},
   "source": [
    "## Fields - school_class and operation_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e18a794-875c-4555-9afa-5cb31ad364a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack Bar Plot of School Class and Operation Type\n",
    "# class_opt_type_cnt = school_df.groupby(['school_class', 'operation_type']).size().reset_index(name='count')\n",
    "# class_opt_type_cnt = class_opt_type_cnt.pivot(index='school_class', columns='operation_type', values='count')\n",
    "# class_opt_type_cnt.reset_index(inplace=True)\n",
    "# class_opt_type_cnt['school_class'] = pd.Categorical(class_opt_type_cnt['school_class'], [\"elementary\", \"middle\", \"high\"])\n",
    "# class_opt_type_cnt = class_opt_type_cnt.sort_values(\"school_class\")\n",
    "\n",
    "# class_opt_type_cnt.plot(\n",
    "#     x = 'school_class', \n",
    "#     kind = 'barh', \n",
    "#     stacked = True, \n",
    "#     title = 'Stacked Bar Plot of Class and Operation Type', \n",
    "#     mark_right = True) \n",
    "\n",
    "# plt.xlabel('Count')\n",
    "# plt.ylabel('School Calss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db517c-cbe8-4259-854e-35ebecf06f80",
   "metadata": {},
   "source": [
    "## 2.3.3 Subway Data Set (Subways.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb0bde-bff4-4b2e-a5c3-023ffd0369bf",
   "metadata": {},
   "source": [
    "## 2.3.2.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6ec07-34ff-4a3a-bd6b-6946cf72c14e",
   "metadata": {},
   "source": [
    "## Field - subway_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "717293ac-f26e-4a43-8436-a8ad8aa6f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21 subway lines: '1', '2', '3', '4', '5', '6', '7', '8', '9', 'AP', 'B1', 'B2', 'B3', 'B4', 'BD', 'BK', 'DL', 'KC', 'KJ', 'ND', 'US'\n"
     ]
    }
   ],
   "source": [
    "subway_line_list = []\n",
    "for subway_line in subway_df[\"subway_line\"].drop_duplicates().tolist():\n",
    "    subway_line_list += subway_line.split(\",\")\n",
    "\n",
    "subway_line_list = list(set(subway_line_list))\n",
    "subway_line_list.sort()\n",
    "print(f\"There are {len(subway_line_list)} subway lines: {str(subway_line_list)[1:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a91999e2-03df-4ee0-8f4d-7f2cbf5b3765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations for each line:\n",
      "2     51\n",
      "5     51\n",
      "B1    40\n",
      "7     39\n",
      "6     38\n",
      "B2    38\n",
      "1     36\n",
      "3     33\n",
      "9     30\n",
      "4     26\n",
      "KJ    22\n",
      "B3    17\n",
      "B4    14\n",
      "BD    14\n",
      "DL    13\n",
      "8     11\n",
      "BK     9\n",
      "KC     6\n",
      "AP     5\n",
      "ND     4\n",
      "US     3\n",
      "Name: subway_line, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "subway_line_split = subway_df[[\"station_id\", \"subway_line\"]].copy()\n",
    "subway_line_split['subway_line'] = subway_line_split['subway_line'].str.split(\",\")\n",
    "subway_line_split = subway_line_split.explode('subway_line')\n",
    "print(\"Number of stations for each line:\")\n",
    "print(subway_line_split[\"subway_line\"].dropna().astype(\"str\").value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2356b-68cc-4b28-889d-bfc1f04e5b2e",
   "metadata": {},
   "source": [
    "## 2.3.3.2 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb637b-7654-47b4-a7a5-09f6ebe428bf",
   "metadata": {},
   "source": [
    "## Fields - latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c0a8a74-9547-4953-970a-51276eb88af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter Plot of Latitude and Longitude with city labels\n",
    "# plt.scatter(school_df['longitude'], school_df['latitude'], color='blue', label='School')\n",
    "# plt.scatter(subway_df['longitude'], subway_df['latitude'], color='green', label='Subway')\n",
    "# plt.title('Latitude and Longitude of Schools and Subways')\n",
    "# plt.xlabel('Longitude')\n",
    "# plt.ylabel('Latitude')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73df4e-14b3-458a-bd90-8b33eea844e9",
   "metadata": {},
   "source": [
    "# 3 Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d2abc-4909-4953-ae22-f85508f33b3b",
   "metadata": {},
   "source": [
    "## 3.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f876d9-c41d-44d6-a209-945e49aae6d2",
   "metadata": {},
   "source": [
    "## 3.1.1 Price Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce41e246-612c-4bba-8859-3cc8d957e310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns have missing values:\n",
      "total_parking_capacity_in_site has 91813 (5.7%) missing value.\n",
      "tallest_building_in_sites has 9 (0.0%) missing value.\n",
      "lowest_building_in_sites has 9 (0.0%) missing value.\n",
      "heat_type has 2017 (0.1%) missing value.\n",
      "heat_fuel has 9667 (0.6%) missing value.\n",
      "room_count has 691 (0.0%) missing value.\n",
      "bathroom_count has 691 (0.0%) missing value.\n",
      "front_door_structure has 13892 (0.9%) missing value.\n"
     ]
    }
   ],
   "source": [
    "print_missing_val_count(price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b785504c-cbab-49df-94c5-257463439135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest_building_in_sites is NULL if and only if tallest_building_in_sites is NULL: True\n"
     ]
    }
   ],
   "source": [
    "# NULL values in lowest_building_in_sites and tallest_building_in_sites\n",
    "print(\"lowest_building_in_sites is NULL if and only if tallest_building_in_sites is NULL:\", \\\n",
    "(price_df['lowest_building_in_sites'].isnull() == price_df['tallest_building_in_sites'].isnull()).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89138b11-42fe-4bdd-9019-da74f5bd16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_count is NULL if and only if bathroom_count is NULL: True\n"
     ]
    }
   ],
   "source": [
    "# NULL values in room_count and bathroom_count\n",
    "print(\"room_count is NULL if and only if bathroom_count is NULL:\", \\\n",
    "(price_df['room_count'].isnull() == price_df['bathroom_count'].isnull()).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37d68470-f75c-465c-b76e-976c0a3db5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012904    NaN\n",
       "Name: heat_fuel, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NULL in heat_type =>  NULL in heat_fuel \n",
    "price_df[price_df['heat_type'].isna()]['heat_fuel'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43e0a3ba-47cd-4cd2-9583-50ecdbf9468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stairway    1146251\n",
       "corridor     415209\n",
       "mixed         26085\n",
       "-                21\n",
       "Name: front_door_structure, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other form of missing value\n",
    "price_df['front_door_structure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1355851-3403-441e-a110-8bdb4e18e344",
   "metadata": {},
   "source": [
    "## 3.1.2 School Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60b2e392-b6e0-481e-ab5b-0c93e390ee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns have missing values:\n",
      "highschool_type has 1459 (76.0%) missing value.\n"
     ]
    }
   ],
   "source": [
    "print_missing_val_count(school_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d64a662-f2d1-4240-beae-3af4fa5d9ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      elementary\n",
       "200        middle\n",
       "Name: school_class, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_df[school_df['highschool_type'].isna()]['school_class'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e153375-53d1-4f99-8052-903aadec2dfb",
   "metadata": {},
   "source": [
    "## 3.1.3 Subway Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bc3838e-0794-46b6-b5e1-67f4e6c2d6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns have missing values:\n",
      "address_by_law has 9 (2.2%) missing value.\n"
     ]
    }
   ],
   "source": [
    "print_missing_val_count(subway_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20778f2a-2ebf-4efe-9191-312af3f4b755",
   "metadata": {},
   "source": [
    "## 3.2 Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304f08d-34e1-4a6d-beeb-653c7517e755",
   "metadata": {},
   "source": [
    "## 3.2.1 Price Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a14f218-dd97-4db2-b504-ef024e3b2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in tallest_building_in_sites has been imputed.\n",
      "Missing values in lowest_building_in_sites has been imputed.\n"
     ]
    }
   ],
   "source": [
    "# Standardized Dataframe\n",
    "price_std = price_df.copy()\n",
    "\n",
    "# Fill missing values with \"-\"\n",
    "price_std[['heat_type', 'heat_fuel', 'front_door_structure']] = \\\n",
    "    price_std[['heat_type', 'heat_fuel', 'front_door_structure']].fillna('-')\n",
    "\n",
    "# Fill missing values with 0\n",
    "price_std[['room_count', 'bathroom_count', 'total_parking_capacity_in_site']] = \\\n",
    "    price_std[[ 'room_count', 'bathroom_count', 'total_parking_capacity_in_site']].fillna(0)\n",
    "\n",
    "# Impute missing values using KNN\n",
    "knn_imputation(price_std, ['longitude', 'latitude'], 'tallest_building_in_sites')\n",
    "\n",
    "knn_imputation(price_std, ['longitude', 'latitude', 'tallest_building_in_sites'], 'lowest_building_in_sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5092c460-2653-46de-a95c-c67416c3f19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe does not have missing values.\n"
     ]
    }
   ],
   "source": [
    "# To ensure all missing values have been handled\n",
    "print_missing_val_count(price_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417091e3-87c0-4bb7-9beb-df7a8af44e6b",
   "metadata": {},
   "source": [
    "## 3.2.2 School Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9946b3c2-54e5-4e57-8aca-93c09d59de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Dataframe\n",
    "school_df_std = school_df.copy()\n",
    "\n",
    "# Fill missing values with \"-\"\n",
    "school_df_std[['highschool_type']] = school_df_std[['highschool_type']].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "767def72-5980-417c-b471-d7c4e02c3d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe does not have missing values.\n"
     ]
    }
   ],
   "source": [
    "# To ensure all missing values have been handled\n",
    "print_missing_val_count(school_df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea291830-a9e9-4d08-b7c8-cdc73888292c",
   "metadata": {},
   "source": [
    "## 3.2.3 Subway Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa7507e5-2f14-411f-b534-f6d5be375965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Dataframe\n",
    "subway_df_std = subway_df.copy()\n",
    "\n",
    "# Fill missing values with \"-\"\n",
    "subway_df_std[['address_by_law']] = subway_df_std[['address_by_law']].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6c18188-8a16-4209-abd1-7aa45f1f205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe does not have missing values.\n"
     ]
    }
   ],
   "source": [
    "# To ensure all missing values have been handled\n",
    "print_missing_val_count(subway_df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84268b7b-31f3-4c6d-a29c-9eedf24650fe",
   "metadata": {},
   "source": [
    "## 3.3 Feature Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29a1a8-202a-4de4-b8ab-73c71397d95d",
   "metadata": {},
   "source": [
    "## 3.3.1 Price Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "078d5c42-6292-43c7-bcfa-13e6d8f988ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down transaction_month_year into two columns\n",
    "price_std['transaction_year'] = price_std['transaction_year_month'].astype(str).str[:4].astype(int)\n",
    "price_std['transaction_month'] = price_std['transaction_year_month'].astype(str).str[4:].astype(int)\n",
    "\n",
    "# Obtain age of the building at the time of transaction\n",
    "price_std['building_age'] = price_std['transaction_year'] - price_std['year_of_completion']\n",
    "\n",
    "# Obtain height different between highest and lowest buildings\n",
    "price_std['diff_height_in_site'] = price_std['tallest_building_in_sites'] - price_std['lowest_building_in_sites']\n",
    "\n",
    "# Obtain ratio of exclusive use area to supply area\n",
    "price_std['excl_use_area_ratio'] = price_std['exclusive_use_area'] / price_std['supply_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54a76c49-1419-4f9f-bf5a-e2dfe5930ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated or non-informative columns\n",
    "price_std = price_std.drop(['key', 'transaction_year_month', 'year_of_completion'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf04c27-becb-4484-b075-e5624760804d",
   "metadata": {},
   "source": [
    "## 3.3.2 School Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d915639-e098-449b-8e4d-5bd8db1b3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain foundation_year from foundation_date\n",
    "school_df_std['foundation_year'] = school_df_std['foundation_date'].str[:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ad1570f-531d-4bd9-aca6-cf1977fc2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of longitude of city 0 is [128.84, 129.24]\n",
      "The range of longitude of city 1 is [126.81, 127.18]\n"
     ]
    }
   ],
   "source": [
    "# Range of longitude for city 0 and city 1\n",
    "for i in [0, 1]:\n",
    "    longitude_list = price_std[price_std['city'] == i]['longitude'].to_list()\n",
    "    print(f\"The range of longitude of city {i} is [{min(longitude_list):.2f}, {max(longitude_list):.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5328fbac-3036-41b1-b170-55c405f2b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain city according to longitude\n",
    "school_df_std['city'] = school_df_std['longitude'].apply(lambda x: 1 if x < 128 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fe2207f-0a5d-4a8c-a4b7-619d43a7448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated or non-informative columns\n",
    "school_df_std = school_df_std.drop(['foundation_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e723c8-68ce-47c2-a48e-c181d06d2ffa",
   "metadata": {},
   "source": [
    "## 3.3.3 Subway Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7bffb54-487b-4202-9910-5aa43d46b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain city according to longitude\n",
    "subway_df_std['city'] = subway_df_std['longitude'].apply(lambda x: 1 if x < 128 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995eef6-fd47-4430-a964-cfc382a5680f",
   "metadata": {},
   "source": [
    "## 3.4 Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6127d4-00fd-4188-9544-82ab419096c5",
   "metadata": {},
   "source": [
    "## 3.4.1 Z-score normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d274694-58a0-4673-b54f-76bbfa9212aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization for numeric features (excluding 'latitude' and 'longitude')\n",
    "numeric_features = [\n",
    "    # original features\n",
    "    'exclusive_use_area',\n",
    "    'floor',\n",
    "    'total_parking_capacity_in_site',\n",
    "    'total_household_count_in_sites',\n",
    "    'apartment_building_count_in_sites',\n",
    "    'supply_area',\n",
    "    'total_household_count_of_area_type',\n",
    "    'room_count',\n",
    "    'bathroom_count',\n",
    "    # calculated features\n",
    "    'excl_use_area_ratio',\n",
    "    'building_age',\n",
    "    'diff_height_in_site']\n",
    "\n",
    "for col in numeric_features:\n",
    "    price_std[col] = zscore(price_std[col], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f0a7630-33e7-4877-a6da-47950f208c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization for 'latitude' and 'longitude'\n",
    "location_features = ['latitude', 'longitude']\n",
    "\n",
    "lat_long_df_all = pd.concat([\n",
    "    price_std[['latitude', 'longitude']], \n",
    "    school_df_std[['latitude', 'longitude']], \n",
    "    subway_df_std[['latitude', 'longitude']]\n",
    "])\n",
    "\n",
    "for col in ['latitude', 'longitude']:\n",
    "    mean = lat_long_df_all[col].mean()\n",
    "    var = lat_long_df_all[col].var()\n",
    "    price_std[col] = (price_std[col] - mean) / var\n",
    "    school_df_std[col] = (school_df_std[col] - mean) / var\n",
    "    subway_df_std[col] = (subway_df_std[col] - mean) / var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06106ce-bbf0-467a-afa0-20473850f261",
   "metadata": {},
   "source": [
    "## 3.4.2 Categorical Feature Handling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f582a93-8b68-4484-9cf9-7bcdd624e36e",
   "metadata": {},
   "source": [
    "## 3.4.2.1 Price Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b9beef2-ef40-468c-9333-9e2156063645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group values with same meaning\n",
    "price_std['transaction_date'] = price_std['transaction_date'] \\\n",
    "    .replace({'21~28': '21~31',\n",
    "              '21~29': '21~31',\n",
    "              '21~30': '21~31'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "389fa759-69a1-4961-815b-d09f5da943e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform one-hot encoding\n",
    "price_std = one_hot_encoding(price_std, 'transaction_date')\n",
    "price_std = one_hot_encoding(price_std, 'front_door_structure')\n",
    "price_std = one_hot_encoding(price_std, 'heat_type')\n",
    "price_std = one_hot_encoding(price_std, 'heat_fuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16042886-5c0f-4e95-a2a2-b0f01128c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final table structure after pre-processing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1601458 entries, 0 to 1601457\n",
      "Data columns (total 37 columns):\n",
      " #   Column                              Non-Null Count    Dtype  \n",
      "---  ------                              --------------    -----  \n",
      " 0   apartment_id                        1601458 non-null  int64  \n",
      " 1   city                                1601458 non-null  int64  \n",
      " 2   exclusive_use_area                  1601458 non-null  float64\n",
      " 3   floor                               1601458 non-null  float64\n",
      " 4   latitude                            1601458 non-null  float64\n",
      " 5   longitude                           1601458 non-null  float64\n",
      " 6   address_by_law                      1601458 non-null  int64  \n",
      " 7   total_parking_capacity_in_site      1601458 non-null  float64\n",
      " 8   total_household_count_in_sites      1601458 non-null  float64\n",
      " 9   apartment_building_count_in_sites   1601458 non-null  float64\n",
      " 10  tallest_building_in_sites           1601458 non-null  float64\n",
      " 11  lowest_building_in_sites            1601458 non-null  float64\n",
      " 12  room_id                             1601458 non-null  int64  \n",
      " 13  supply_area                         1601458 non-null  float64\n",
      " 14  total_household_count_of_area_type  1601458 non-null  float64\n",
      " 15  room_count                          1601458 non-null  float64\n",
      " 16  bathroom_count                      1601458 non-null  float64\n",
      " 17  transaction_real_price              1601458 non-null  int64  \n",
      " 18  transaction_year                    1601458 non-null  int32  \n",
      " 19  transaction_month                   1601458 non-null  int32  \n",
      " 20  building_age                        1601458 non-null  float64\n",
      " 21  diff_height_in_site                 1601458 non-null  float64\n",
      " 22  excl_use_area_ratio                 1601458 non-null  float64\n",
      " 23  transaction_date_1~10               1601458 non-null  int64  \n",
      " 24  transaction_date_11~20              1601458 non-null  int64  \n",
      " 25  transaction_date_21~31              1601458 non-null  int64  \n",
      " 26  front_door_structure_mixed          1601458 non-null  int64  \n",
      " 27  front_door_structure_stairway       1601458 non-null  int64  \n",
      " 28  front_door_structure_corridor       1601458 non-null  int64  \n",
      " 29  front_door_structure_-              1601458 non-null  int64  \n",
      " 30  heat_type_-                         1601458 non-null  int64  \n",
      " 31  heat_type_district                  1601458 non-null  int64  \n",
      " 32  heat_type_central                   1601458 non-null  int64  \n",
      " 33  heat_type_individual                1601458 non-null  int64  \n",
      " 34  heat_fuel_-                         1601458 non-null  int64  \n",
      " 35  heat_fuel_cogeneration              1601458 non-null  int64  \n",
      " 36  heat_fuel_gas                       1601458 non-null  int64  \n",
      "dtypes: float64(16), int32(2), int64(19)\n",
      "memory usage: 439.9 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Final table structure after pre-processing:\")\n",
    "price_std.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab317b51-e6ff-4ff9-ba92-ad57f6f5e2e9",
   "metadata": {},
   "source": [
    "## 3.4.2.2 School Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27b35de8-47a6-4d2a-9e74-d4332ae22afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform school_code into integer\n",
    "codes, uniques = pd.factorize(school_df_std['school_code'])\n",
    "school_df_std['school_code'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c785b9a-dd99-4c70-9a58-c6883bf382b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding\n",
    "school_df_std = one_hot_encoding(school_df_std, 'school_class')\n",
    "school_df_std = one_hot_encoding(school_df_std, 'operation_type')\n",
    "school_df_std = one_hot_encoding(school_df_std, 'highschool_type')\n",
    "school_df_std = one_hot_encoding(school_df_std, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8b656fd-fc7e-442f-9388-c3d27cb0bd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final table structure after pre-processing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1921 entries, 0 to 1920\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   school_code                  1921 non-null   int64  \n",
      " 1   latitude                     1921 non-null   float64\n",
      " 2   longitude                    1921 non-null   float64\n",
      " 3   address_by_law               1921 non-null   int64  \n",
      " 4   foundation_year              1921 non-null   int32  \n",
      " 5   city                         1921 non-null   int64  \n",
      " 6   school_class_high            1921 non-null   int64  \n",
      " 7   school_class_middle          1921 non-null   int64  \n",
      " 8   school_class_elementary      1921 non-null   int64  \n",
      " 9   operation_type_public        1921 non-null   int64  \n",
      " 10  operation_type_private       1921 non-null   int64  \n",
      " 11  operation_type_national      1921 non-null   int64  \n",
      " 12  highschool_type_general      1921 non-null   int64  \n",
      " 13  highschool_type_objective    1921 non-null   int64  \n",
      " 14  highschool_type_specialized  1921 non-null   int64  \n",
      " 15  highschool_type_autonomous   1921 non-null   int64  \n",
      " 16  highschool_type_-            1921 non-null   int64  \n",
      " 17  gender_female                1921 non-null   int64  \n",
      " 18  gender_both                  1921 non-null   int64  \n",
      " 19  gender_male                  1921 non-null   int64  \n",
      "dtypes: float64(2), int32(1), int64(17)\n",
      "memory usage: 292.8 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Final table structure after pre-processing:\")\n",
    "school_df_std.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbf2f3-8ee5-48e0-b45f-320952a3be41",
   "metadata": {},
   "source": [
    "## 3.4.2.3 Subway Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14987dbe-8403-4b9c-b0af-673dc76a706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for subway_line (need to split by commas first)\n",
    "for subway_line in subway_line_list:\n",
    "    new_column = \"line_\" + subway_line\n",
    "    subway_df_std[new_column] = subway_df_std['subway_line'] \\\n",
    "        .apply(lambda col: 1 if subway_line in list(col.split(',')) else 0)\n",
    "\n",
    "subway_df_std = subway_df_std.drop('subway_line', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c10126b-f507-4236-9295-098a542db9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final table structure after pre-processing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 405 entries, 0 to 404\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   station_id      405 non-null    int64  \n",
      " 1   latitude        405 non-null    float64\n",
      " 2   longitude       405 non-null    float64\n",
      " 3   address_by_law  405 non-null    object \n",
      " 4   city            405 non-null    int64  \n",
      " 5   line_1          405 non-null    int64  \n",
      " 6   line_2          405 non-null    int64  \n",
      " 7   line_3          405 non-null    int64  \n",
      " 8   line_4          405 non-null    int64  \n",
      " 9   line_5          405 non-null    int64  \n",
      " 10  line_6          405 non-null    int64  \n",
      " 11  line_7          405 non-null    int64  \n",
      " 12  line_8          405 non-null    int64  \n",
      " 13  line_9          405 non-null    int64  \n",
      " 14  line_AP         405 non-null    int64  \n",
      " 15  line_B1         405 non-null    int64  \n",
      " 16  line_B2         405 non-null    int64  \n",
      " 17  line_B3         405 non-null    int64  \n",
      " 18  line_B4         405 non-null    int64  \n",
      " 19  line_BD         405 non-null    int64  \n",
      " 20  line_BK         405 non-null    int64  \n",
      " 21  line_DL         405 non-null    int64  \n",
      " 22  line_KC         405 non-null    int64  \n",
      " 23  line_KJ         405 non-null    int64  \n",
      " 24  line_ND         405 non-null    int64  \n",
      " 25  line_US         405 non-null    int64  \n",
      "dtypes: float64(2), int64(23), object(1)\n",
      "memory usage: 82.4+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Final table structure after pre-processing:\")\n",
    "subway_df_std.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f259ae-afa7-4829-87ba-b5962fca7201",
   "metadata": {},
   "source": [
    "## 3.5 Export Data Pre-processing Result to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fff93eb8-9efe-4dbf-ac8f-d88dc1f3b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_std.to_csv('price_std.csv', index=False)\n",
    "school_df_std.to_csv('school_std.csv', index=False)\n",
    "subway_df_std.to_csv('subway_std.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecab2a-29ad-4425-8f23-e4a8b66af1a6",
   "metadata": {},
   "source": [
    "# 4 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad59b9-193c-4686-ac0f-66d0913c96ee",
   "metadata": {},
   "source": [
    "## 4.1 Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3aa9b22-3b74-4273-8815-0c5cba05513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pre-processed Price data set\n",
    "price_std = pd.read_csv('price_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc80aece-de83-4df1-ab23-c63a9522ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y dataframe (Without id columns and address by law)\n",
    "X_all = price_std \\\n",
    "    .drop(['apartment_id',\n",
    "           'room_id',\n",
    "           'address_by_law',\n",
    "           'transaction_real_price'],\n",
    "          axis=1)\n",
    "\n",
    "y_all = price_std['transaction_real_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6476c0cb-4bb1-489b-aac4-c38fb83195e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Price data set into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8b9fb-4f21-4693-b702-5dba4a61b3e1",
   "metadata": {},
   "source": [
    "## 4.1.1 Constant (Mean) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98aab6a8-d76d-475c-adf6-8ebf4ccb6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of price in training set is 4.021e+08.\n",
      "The rooted MSE of mean model is 3.232e+08.\n"
     ]
    }
   ],
   "source": [
    "# Mean model\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "print(f\"The mean of price in training set is {y_mean:.4}.\")\n",
    "print(f\"The rooted MSE of mean model is {np.sqrt(mean_squared_error(y_test, [y_mean] * len(y_test))):.4}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0683e-89d6-45ab-91d0-b0e318c0b04a",
   "metadata": {},
   "source": [
    "## 4.1.2 Other Basic Models - Linear, Ridge, Tree, Neural Network Regression, K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d8eff-6c80-4027-b58c-ffc075ed163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- LinearRegression ----------\n",
      "Rooted-MSE: 1.884e+08\n",
      "MAE: 1.184e+08\n",
      "Adjusted R-Squared: 0.6601\n",
      "\n",
      "---------- Ridge ----------\n",
      "Rooted-MSE: 1.894e+08\n",
      "MAE: 1.18e+08\n",
      "Adjusted R-Squared: 0.6567\n",
      "\n",
      "---------- DecisionTreeRegressor ----------\n",
      "Rooted-MSE: 4.439e+07\n",
      "MAE: 1.916e+07\n",
      "Adjusted R-Squared: 0.9811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit Basic Models\n",
    "basic_regressors = lambda model: [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=100, random_state=2024),\n",
    "    DecisionTreeRegressor(random_state=2024),\n",
    "    MLPRegressor(hidden_layer_sizes=(20,10,5,10,5), max_iter=20),\n",
    "    KNeighborsRegressor(p=1)\n",
    "]\n",
    "\n",
    "predict_with_regressors(basic_regressors, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252f95c-ec64-4c20-a26e-33d025941ee5",
   "metadata": {},
   "source": [
    "## 4.2 Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5567b08-07c8-4646-bd2b-7f88b7e6164e",
   "metadata": {},
   "source": [
    "## 4.2.1 Drop Highly Correlated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d836b9c-aaf3-4d2d-9b97-9261cb648717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Upper triangle of correlation matrix\n",
    "upper_corr_matrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Features with correlation > 0.9\n",
    "col_to_drop = [col for col in upper_corr_matrix.columns if any(upper_corr_matrix[col] > 0.9)]\n",
    "\n",
    "print(\"The column (left) will be dropped because they are highly correlated to another column (right).\")\n",
    "for col in col_to_drop:\n",
    "    print(f\"{col}: {upper_corr_matrix[upper_corr_matrix[col] > 0.9].index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21ce65-1f52-473e-ae74-305b068a468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the highly correlated columns\n",
    "X_train_reduced = X_train.drop(col_to_drop, axis=1, inplace=False)\n",
    "X_test_reduced = X_test.drop(col_to_drop, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b97e68-b41a-432f-b8c5-fbdef64cafb5",
   "metadata": {},
   "source": [
    "## 4.2.2 Feature Impartances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777dc4d2-7c63-4009-8e82-642be0b3afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Decision Tree\n",
    "dtr = DecisionTreeRegressor(random_state=2024)\n",
    "dtr.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Feature Importance from Tree Model\n",
    "feat_import_df = pd.DataFrame({'feature': dtr.feature_names_in_,\n",
    "                               'importance': dtr.feature_importances_}) \\\n",
    "    .sort_values('importance', ascending=False)\n",
    "\n",
    "feat_import_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a6820-7efa-498e-b820-ee80f7af2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 highest feature importance columns\n",
    "top_5_cols = feat_import_df[\"feature\"].tolist()[:5]\n",
    "X_train_5cols = X_train_reduced[top_5_cols]\n",
    "X_test_5cols = X_test_reduced[top_5_cols]\n",
    "\n",
    "print(f\"The top 5 highest feature importance columns are {str(top_5_cols)[1:-1]}.\")\n",
    "print(\"The peformance of models trained using only these features are shown as follows:\\n\")\n",
    "predict_with_regressors(basic_regressors, X_train_5cols, X_test_5cols, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c89347-9097-4df9-baaf-57c7477fab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 2 highest feature importance columns\n",
    "top_2_cols = feat_import_df[\"feature\"].tolist()[:2]\n",
    "X_train_2cols = X_train_reduced[top_2_cols]\n",
    "X_test_2cols = X_test_reduced[top_2_cols]\n",
    "\n",
    "# Fit models using the top 2 features\n",
    "print(f\"The top 2 highest feature importance columns are {str(top_2_cols)[1:-1]}.\")\n",
    "print(\"The peformance of models trained using only these features are shown as follows:\\n\")\n",
    "predict_with_regressors(basic_regressors, X_train_2cols, X_test_2cols, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a1a24-8147-4f94-a3c6-f8fe32ad21a4",
   "metadata": {},
   "source": [
    "## 4.2.3 Feature Impartances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b55a8c-5ca9-4c4f-8ee3-c120e6e11f83",
   "metadata": {},
   "source": [
    "## 4.2.3.1 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c57baf-f4ab-4c0e-89f5-2a6e76ba83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_all)\n",
    "\n",
    "# Transform training set and test set\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Model Performance\n",
    "predict_with_regressors(basic_regressors, X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be5427-4b15-4631-bfb0-9dd80c6a09eb",
   "metadata": {},
   "source": [
    "## 4.2.3.2 Partial Least Squares (PLS) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37361806-b219-43b0-b142-cd3b7f7f3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PLS\n",
    "pls = PLSRegression(n_components=5)\n",
    "pls.fit(X_all, y_all)\n",
    "\n",
    "# Transform training set and test set\n",
    "X_train_pls = pca.transform(X_train)\n",
    "X_test_pls = pca.transform(X_test)\n",
    "\n",
    "# Model Performance\n",
    "predict_with_regressors(basic_regressors, X_train_pls, X_test_pls, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a32055-e432-4933-90af-1fe8383b3e01",
   "metadata": {},
   "source": [
    "## 4.3 Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9a45e-83c2-4ef2-8d59-38c6c4d6f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Tree\n",
    "bagging_tree = BaggingRegressor(DecisionTreeRegressor(random_state=2024), n_estimators=11, random_state=2024, bootstrap_features=True)\n",
    "predict_with_regressor(bagging_tree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0710f84-d94c-4cb6-b1b8-07cbc05f8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestRegressor(n_estimators = 11, random_state=2024)\n",
    "predict_with_regressor(random_forest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a61822-a251-4673-821f-6ce3a9b3cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Tree\n",
    "adaboost_tree = AdaBoostRegressor(DecisionTreeRegressor(random_state=2024), n_estimators=11, random_state=2024)\n",
    "predict_with_regressor(adaboost_tree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf70e6-52f9-49a4-8813-f6353f96c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting for Regression\n",
    "grad_boost = GradientBoostingRegressor(n_estimators=11, random_state=2024)\n",
    "predict_with_regressor(grad_boost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3256511-7683-48f4-a32a-7803d14d7698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1f7b4-7880-48a6-bd5c-c3a862b2600a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
